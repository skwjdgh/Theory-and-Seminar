import streamlit as st
from streamlit_mic_recorder import mic_recorder
import whisper
import io
import os
import platform
import threading
import subprocess
import pyttsx3
from langchain_ollama import ChatOllama, OllamaEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.documents import Document
from langchain_core.runnables import RunnablePassthrough
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain.agents import Tool, initialize_agent, AgentType
from langchain_community.vectorstores import FAISS
from langchain.memory import ConversationBufferMemory

# 1. ë¦¬ì†ŒìŠ¤ ìºì‹œì™€ ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì´ˆê¸°í™” ë¶„ë¦¬
@st.cache_resource
def load_whisper_model():
    model = whisper.load_model("base")
    return model

@st.cache_resource
def load_embeddings():
    return OllamaEmbeddings(model="llama3.1", base_url="http://localhost:11434")

@st.cache_resource
def load_faiss_index(embeddings):
    docs = [Document(page_content="íšŒì˜ëŠ” ë§¤ì£¼ ì›”ìš”ì¼ ì˜¤í›„ 3ì‹œì— ì§„í–‰ë©ë‹ˆë‹¤."),
            Document(page_content="ê°œì¸ ë¹„ì„œëŠ” ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì¹œì ˆí•˜ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")]
    return FAISS.from_documents(docs, embeddings)

# ë²„ì „ ê³ ì •ì€ requirements.txtì—ì„œ ê´€ë¦¬í•˜ì„¸ìš”

whisper_model = load_whisper_model()
embeddings = load_embeddings()
faiss_db = load_faiss_index(embeddings)
retriever = faiss_db.as_retriever()

# 2. LLM ë° í”„ë¡¬í”„íŠ¸ ì²´ì¸ êµ¬ì„± (íƒ€ì„ì•„ì›ƒ ë° ì¬ì‹œë„ ë¡œì§ í¬í•¨)
llm = ChatOllama(model="llama3.1", base_url="http://localhost:11434", temperature=0.7, timeout_seconds=10)

prompt = ChatPromptTemplate.from_template(
    """ë‹¹ì‹ ì€ ì „ë¬¸ ê°œì¸ ë¹„ì„œì…ë‹ˆë‹¤. ë‹¤ìŒ ê·œì¹™ì„ ì¤€ìˆ˜í•˜ì„¸ìš”:
    1. ì‚¬ìš©ì ìš”ì²­ì„ ì •í™•íˆ ì´í•´í•´ ë‹µë³€
    2. ì¹œì ˆí•œ ë§íˆ¬ ì‚¬ìš© (ì¡´ëŒ“ë§)
    3. ë‹µë³€ì€ ìµœëŒ€ 3ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ

    ìš”ì²­: {message}
    ë‹µë³€:"""
)

base_chain = prompt | llm | StrOutputParser()

# 3. ì„¸ì…˜ë³„ ë©”ëª¨ë¦¬
if 'memory' not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(return_messages=True)
conversation = RunnableWithMessageHistory(
    base_chain,
    lambda session_id: st.session_state.memory,
    input_messages_key="message",
    history_messages_key="history"
)

# 4. RAG ì²´ì¸ êµ¬ì„± (invoke ì…ë ¥ ìˆ˜ì •)
rag_prompt = ChatPromptTemplate.from_template("ë¬¸ë§¥: {context}\nì§ˆë¬¸: {question}\në‹µë³€:")
rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | rag_prompt | llm | StrOutputParser()
)

# 5. Tool í•¨ìˆ˜ ì •ì˜ (ëŒë‹¤ ëŒ€ì‹  í•¨ìˆ˜)
def draft_email_tool(input_text: str) -> str:
    return base_chain.invoke({"message": f"ë‹¤ìŒ ë‚´ìš©ìœ¼ë¡œ ì´ë©”ì¼ì„ ì‘ì„±í•´ì£¼ì„¸ìš”: {input_text}"})

def schedule_meeting_tool(input_text: str) -> str:
    return base_chain.invoke({"message": f"{input_text} ì¼ì • ì¡ì•„ì¤˜"})

def qna_tool(input_text: str) -> str:
    return base_chain.invoke({"message": input_text})

tools = [
    Tool(name="DraftEmail", func=draft_email_tool, description="ë‚´ìš©ì„ ì…ë ¥í•˜ë©´ ì´ë©”ì¼ì„ ì‘ì„±í•´ë“œë¦½ë‹ˆë‹¤."),
    Tool(name="ScheduleMeeting", func=schedule_meeting_tool, description="íšŒì˜ ì¼ì •ì„ ì¡°ìœ¨í•©ë‹ˆë‹¤."),
    Tool(name="QnA", func=qna_tool, description="ì¼ë°˜ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.")
]
agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True, memory=st.session_state.memory)

# 6. Whisper ìŒì„± ì¸ì‹ (ffmpeg ë³€í™˜ ì§€ì›)
def transcode_to_wav(audio_bytes: bytes) -> io.BytesIO:
    temp_in = '/tmp/input_audio'
    temp_out = '/tmp/output.wav'
    with open(temp_in, 'wb') as f:
        f.write(audio_bytes)
    subprocess.run(['ffmpeg', '-y', '-i', temp_in, temp_out], check=False)
    wav_bio = io.BytesIO(open(temp_out, 'rb').read())
    wav_bio.name = 'audio.wav'
    return wav_bio


def recognize_speech_web(audio_bytes):
    try:
        audio_bio = transcode_to_wav(audio_bytes)
        result = whisper_model.transcribe(audio_bio, language="ko")
        return result.get("text", None)
    except Exception as e:
        st.error(f"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {e}")
        return None

# 7. Streamlit UI
st.title("ğŸ¤– ê°œì¸ìš© AI ë¹„ì„œ ì„œë¹„ìŠ¤")
st.subheader("í…ìŠ¤íŠ¸/ìŒì„± ì…ë ¥ â†’ Llama 3.1 ê¸°ë°˜ ë‹µë³€")
st.write("ë§ˆì´í¬ ì‚¬ìš© ì‹œ ë¸Œë¼ìš°ì € ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.")

input_mode = st.radio("ì…ë ¥ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”", ("í…ìŠ¤íŠ¸", "ìŒì„±"), horizontal=True)
input_text = ""

if input_mode == "í…ìŠ¤íŠ¸":
    input_text = st.text_input("ë¹„ì„œì—ê²Œ í•  ë§ì„ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: ì˜¤ëŠ˜ ì¼ì • ì•Œë ¤ì¤˜")
elif input_mode == "ìŒì„±":
    st.write("ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§ˆì´í¬ë¡œ ë§í•˜ì„¸ìš” ğŸ‘‡")
    audio = mic_recorder(start_prompt="ğŸ¤ ë§í•˜ê¸° ì‹œì‘", stop_prompt="â¹ï¸ ë…¹ìŒ ì¢…ë£Œ", key="recorder")
    if audio:
        st.audio(audio['bytes'], format="audio/webm")
        input_text = recognize_speech_web(audio['bytes'])

# 8. ìš”ì²­ ë¶„ê¸° ì²˜ë¦¬ ë° ì˜ˆì™¸ ì²˜ë¦¬
if input_text:
    if "ì´ë©”ì¼" in input_text or "ì¼ì •" in input_text:
        response = agent.run(input_text)
    elif "íšŒì˜" in input_text or "ì •ë³´" in input_text:
        response = rag_chain.invoke({"question": input_text})
    else:
        response = conversation.invoke(
            {"message": input_text},
            config={"configurable": {"session_id": "user-session"}}
        )

    # 9. ì‘ë‹µ ì¶œë ¥
    st.subheader("ğŸ“ ë¹„ì„œ ë‹µë³€")
    st.write(response)

    # 10. ë¹„ë™ê¸° TTS ì²˜ë¦¬
    def tts_play(text: str):
        try:
            engine = pyttsx3.init()
            engine.say(text)
            engine.runAndWait()
        except Exception:
            pass

    st.subheader("ğŸ”Š ìŒì„± ì¶œë ¥")
    threading.Thread(target=tts_play, args=(response,), daemon=True).start()

    # 11. ëŒ€í™” ì´ë ¥ ê´€ë¦¬ (ìµœëŒ€ 50ê°œ)
    if 'history' not in st.session_state:
        st.session_state.history = []
    st.session_state.history.append(("ğŸ‘¤ ì‚¬ìš©ì", input_text))
    st.session_state.history.append(("ğŸ¤– ë¹„ì„œ", response))
    if len(st.session_state.history) > 50:
        st.session_state.history = st.session_state.history[-50:]

    st.subheader("ğŸ—‚ï¸ ëŒ€í™” ì´ë ¥")
    for role, msg in st.session_state.history:
        st.text(f"{role}: {msg}")
