################################################################################
# 1. Whisper ëª¨ë¸ ì´ˆê¸°í™”
################################################################################
import streamlit as st
from streamlit_mic_recorder import mic_recorder  # ì›¹ ë§ˆì´í¬ ì…ë ¥
import whisper  # ìŒì„± ì¸ì‹
import io  # ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ì²˜ë¦¬
import platform
import os

################################################################################
# 2. LangChain ë° Ollama ëª¨ë“ˆ ë¡œë”©
################################################################################
from langchain_ollama import ChatOllama, OllamaEmbeddings  # Ollama ëª¨ë¸ ì—°ë™, ì„ë² ë”©
from langchain_core.prompts import ChatPromptTemplate  # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
from langchain_core.output_parsers import StrOutputParser  # ì¶œë ¥ íŒŒì„œ
from langchain.agents import Tool, initialize_agent, AgentType  # ì—ì´ì „íŠ¸ ë„êµ¬
from langchain.memory import ConversationBufferMemory  # ëŒ€í™” ë©”ëª¨ë¦¬ ì €ì¥
from langchain.chains import ConversationChain  # ëŒ€í™”í˜• ì²´ì¸
from langchain_community.vectorstores import FAISS  # ë²¡í„° ê²€ìƒ‰
from langchain_core.documents import Document  # ë¬¸ì„œ
from langchain_core.runnables import RunnablePassthrough  # RAGìš© íë¦„ êµ¬ì„±

################################################################################
# 3. Whisper ìŒì„± ì¸ì‹ ëª¨ë¸ ìºì‹œ ë¡œë”©
################################################################################
@st.cache_resource
def load_whisper_model():
    return whisper.load_model("base")

whisper_model = load_whisper_model()

################################################################################
# 4. ìŒì„± ì¸ì‹ í•¨ìˆ˜ ì •ì˜
################################################################################
def recognize_speech_web(audio_bytes):
    try:
        audio_bio = io.BytesIO(audio_bytes)
        audio_bio.name = 'audio.webm'
        result = whisper_model.transcribe(audio_bio, language="ko")
        return result["text"]
    except Exception as e:
        st.error(f"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {e}")
        return None

################################################################################
# 5. LLM ë° ê¸°ë³¸ ëŒ€í™” ì²´ì¸ êµ¬ì„±
################################################################################
llm = ChatOllama(model="llama3.1", base_url="http://localhost:11434", temperature=0.7)

prompt = ChatPromptTemplate.from_template(
    """ë‹¹ì‹ ì€ ì „ë¬¸ ê°œì¸ ë¹„ì„œì…ë‹ˆë‹¤. ë‹¤ìŒ ê·œì¹™ì„ ì¤€ìˆ˜í•˜ì„¸ìš”:
    1. ì‚¬ìš©ì ìš”ì²­ì„ ì •í™•íˆ ì´í•´í•´ ë‹µë³€
    2. ì¹œì ˆí•œ ë§íˆ¬ ì‚¬ìš© (ì¡´ëŒ“ë§)
    3. ë‹µë³€ì€ 3ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ

    ìš”ì²­: {message}
    ë‹µë³€:"""
)

chain = prompt | llm | StrOutputParser()

################################################################################
# 6. ëŒ€í™” ë©”ëª¨ë¦¬ ë° ConversationChain
################################################################################
memory = ConversationBufferMemory(memory_key="history", return_messages=True)
conversation = ConversationChain(llm=llm, memory=memory, verbose=True)

################################################################################
# 7. ë¬¸ì„œ ê¸°ë°˜ RAG ì²´ì¸ êµ¬ì„±
################################################################################
documents = [
    Document(page_content="íšŒì˜ëŠ” ë§¤ì£¼ ì›”ìš”ì¼ ì˜¤í›„ 3ì‹œì— ì§„í–‰ë©ë‹ˆë‹¤."),
    Document(page_content="ê°œì¸ ë¹„ì„œëŠ” ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì¹œì ˆí•˜ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
]
embeddings = OllamaEmbeddings(model="llama3.1", base_url="http://localhost:11434")
db = FAISS.from_documents(documents, embeddings)
retriever = db.as_retriever()

rag_prompt = ChatPromptTemplate.from_template("ë¬¸ë§¥: {context}\nì§ˆë¬¸: {question}\në‹µë³€:")
rag_chain = ({"context": retriever, "question": RunnablePassthrough()} | rag_prompt | llm | StrOutputParser())

################################################################################
# 8. íˆ´ ì •ì˜ (ì—ì´ì „íŠ¸ê°€ í™œìš©í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥)
################################################################################
tools = [
    Tool(
        name="DraftEmail",
        func=lambda ctx: chain.invoke({"message": f"ë‹¤ìŒ ë‚´ìš©ìœ¼ë¡œ ì´ë©”ì¼ì„ ì‘ì„±í•´ì£¼ì„¸ìš”: {ctx}"}),
        description="ì£¼ì–´ì§„ ë‚´ìš©ìœ¼ë¡œ ì´ë©”ì¼ì„ ì‘ì„±í•©ë‹ˆë‹¤."
    ),
    Tool(
        name="ScheduleMeeting",
        func=lambda date, topic: chain.invoke({"message": f"{date}ì— {topic} íšŒì˜ ì¼ì •ì„ ì¡ì•„ì£¼ì„¸ìš”."}),
        description="íŠ¹ì • ë‚ ì§œì™€ ì£¼ì œë¡œ íšŒì˜ ì¼ì •ì„ ì¡ìŠµë‹ˆë‹¤."
    ),
    Tool(
        name="QnA",
        func=lambda question: chain.invoke({"message": question}),
        description="ì¼ë°˜ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤."
    )
]

################################################################################
# 9. ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
################################################################################
agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True, memory=memory)

################################################################################
# 10. Streamlit UI êµ¬ì„±
################################################################################
st.title("ğŸ¤– ê°œì¸ìš© AI ë¹„ì„œ ì„œë¹„ìŠ¤")
st.subheader("í…ìŠ¤íŠ¸/ìŒì„± ì…ë ¥ â†’ Llama 3.1 ê¸°ë°˜ ë‹µë³€")
st.write("ë§ˆì´í¬ ì‚¬ìš© ì‹œ ë¸Œë¼ìš°ì € ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”. (ìµœì´ˆ 1íšŒ í•„ìš”)")

input_mode = st.radio("ì…ë ¥ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”", ("í…ìŠ¤íŠ¸", "ìŒì„±"), horizontal=True)
input_text = ""

if input_mode == "í…ìŠ¤íŠ¸":
    input_text = st.text_input("ë¹„ì„œì—ê²Œ í•  ë§ì„ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: ì˜¤ëŠ˜ ì¼ì • ì•Œë ¤ì¤˜")
elif input_mode == "ìŒì„±":
    st.write("ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§ˆì´í¬ë¡œ ë§í•˜ì„¸ìš” ğŸ‘‡")
    audio = mic_recorder(start_prompt="ğŸ¤ ë§í•˜ê¸° ì‹œì‘", stop_prompt="â¹ï¸ ë…¹ìŒ ì¢…ë£Œ", key="recorder")
    if audio:
        st.audio(audio['bytes'], format="audio/webm")
        input_text = recognize_speech_web(audio['bytes'])

################################################################################
# 11. ì‚¬ìš©ì ìš”ì²­ ë¶„ê¸° ì²˜ë¦¬ ë° ì‘ë‹µ ìƒì„±
################################################################################
if input_text:
    if "ì´ë©”ì¼" in input_text or "ì¼ì •" in input_text:
        response = agent.run(input_text)
    elif "íšŒì˜" in input_text or "ì •ë³´" in input_text:
        response = rag_chain.invoke(input_text)
    else:
        response = conversation.predict(input=input_text)

    ################################################################################
    # 12. ì‘ë‹µ ì¶œë ¥ ë° TTS ì²˜ë¦¬
    ################################################################################
    st.subheader("ğŸ“ ë¹„ì„œ ë‹µë³€")
    st.write(response)

    st.subheader("ğŸ”Š ìŒì„± ì¶œë ¥")
    tts_command = None
    if platform.system() == "Darwin":
        tts_command = f'say "{response}"'
    elif platform.system() == "Windows":
        tts_command = f'edge-tts --text "{response}" --write-media output.mp3 && start output.mp3'
    elif platform.system() == "Linux":
        tts_command = f'tts --text "{response}" --out_path output.wav && aplay output.wav'

    if tts_command:
        os.system(tts_command)

    ################################################################################
    # 13. ëŒ€í™” ì´ë ¥ ì €ì¥ ë° ì¶œë ¥
    ################################################################################
    if 'history' not in st.session_state:
        st.session_state.history = []
    st.session_state.history.append(("ğŸ‘¤ ì‚¬ìš©ì", input_text))
    st.session_state.history.append(("ğŸ¤– ë¹„ì„œ", response))

    st.subheader("ğŸ—‚ï¸ ëŒ€í™” ì´ë ¥")
    for role, msg in st.session_state.history:
        st.markdown(f"**{role}:** {msg}")
