################################################################################
# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ê¸°ë³¸ ì„¤ì •
################################################################################
import streamlit as st
from streamlit_mic_recorder import mic_recorder
import whisper
import io
import os
import platform
import pyttsx3

from langchain_ollama import ChatOllama, OllamaEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.documents import Document
from langchain_core.runnables import RunnablePassthrough
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain.agents import Tool, initialize_agent, AgentType
from langchain_community.vectorstores import FAISS
from langchain.memory import ConversationBufferMemory

################################################################################
# 2. Whisper ìŒì„± ì¸ì‹ ëª¨ë¸ ì´ˆê¸°í™”
################################################################################
@st.cache_resource
def load_whisper_model():
    return whisper.load_model("base")

whisper_model = load_whisper_model()

def recognize_speech_web(audio_bytes):
    try:
        audio_bio = io.BytesIO(audio_bytes)
        audio_bio.name = 'audio.webm'
        result = whisper_model.transcribe(audio_bio, language="ko")
        return result["text"]
    except Exception as e:
        st.error(f"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {e}")
        return None

################################################################################
# 3. LLM ë° ê¸°ë³¸ ëŒ€í™” ì²´ì¸ êµ¬ì„±
################################################################################
llm = ChatOllama(model="llama3.1", base_url="http://localhost:11434", temperature=0.7)

prompt = ChatPromptTemplate.from_template(
    """ë‹¹ì‹ ì€ ì „ë¬¸ ê°œì¸ ë¹„ì„œì…ë‹ˆë‹¤. ë‹¤ìŒ ê·œì¹™ì„ ì¤€ìˆ˜í•˜ì„¸ìš”:
    1. ì‚¬ìš©ì ìš”ì²­ì„ ì •í™•íˆ ì´í•´í•´ ë‹µë³€
    2. ì¹œì ˆí•œ ë§íˆ¬ ì‚¬ìš© (ì¡´ëŒ“ë§)
    3. ë‹µë³€ì€ 3ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ

    ìš”ì²­: {message}
    ë‹µë³€:"""
)

base_chain = prompt | llm | StrOutputParser()

################################################################################
# 4. ëŒ€í™” ë©”ëª¨ë¦¬ ë° ë©”ì‹œì§€ ê¸°ë°˜ ì²´ì¸ êµ¬ì„±
################################################################################
memory = ConversationBufferMemory(return_messages=True)

conversation = RunnableWithMessageHistory(
    base_chain,
    lambda session_id: memory,
    input_messages_key="message",
    history_messages_key="history"
)

################################################################################
# 5. RAG ë¬¸ì„œ ê²€ìƒ‰ ì²´ì¸ êµ¬ì„±
################################################################################
documents = [
    Document(page_content="íšŒì˜ëŠ” ë§¤ì£¼ ì›”ìš”ì¼ ì˜¤í›„ 3ì‹œì— ì§„í–‰ë©ë‹ˆë‹¤."),
    Document(page_content="ê°œì¸ ë¹„ì„œëŠ” ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì¹œì ˆí•˜ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
]

embeddings = OllamaEmbeddings(model="llama3.1", base_url="http://localhost:11434")
db = FAISS.from_documents(documents, embeddings)
retriever = db.as_retriever()

rag_prompt = ChatPromptTemplate.from_template("ë¬¸ë§¥: {context}\nì§ˆë¬¸: {question}\në‹µë³€:")
rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | rag_prompt | llm | StrOutputParser()
)

################################################################################
# 6. LangChain Agent Tool êµ¬ì„±
################################################################################
tools = [
    Tool(
        name="DraftEmail",
        func=lambda input: base_chain.invoke({"message": f"ë‹¤ìŒ ë‚´ìš©ìœ¼ë¡œ ì´ë©”ì¼ì„ ì‘ì„±í•´ì£¼ì„¸ìš”: {input}"}),
        description="ë‚´ìš©ì„ ì…ë ¥í•˜ë©´ ì´ë©”ì¼ì„ ì‘ì„±í•´ë“œë¦½ë‹ˆë‹¤."
    ),
    Tool(
        name="ScheduleMeeting",
        func=lambda input: base_chain.invoke({"message": f"{input} ì¼ì • ì¡ì•„ì¤˜"}),
        description="íšŒì˜ ì¼ì •ì„ ì¡°ìœ¨í•©ë‹ˆë‹¤."
    ),
    Tool(
        name="QnA",
        func=lambda input: base_chain.invoke({"message": input}),
        description="ì¼ë°˜ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤."
    )
]

agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True, memory=memory)

################################################################################
# 7. Streamlit UI êµ¬ì„±
################################################################################
st.title("ğŸ¤– ê°œì¸ìš© AI ë¹„ì„œ ì„œë¹„ìŠ¤")
st.subheader("í…ìŠ¤íŠ¸/ìŒì„± ì…ë ¥ â†’ Llama 3.1 ê¸°ë°˜ ë‹µë³€")
st.write("ë§ˆì´í¬ ì‚¬ìš© ì‹œ ë¸Œë¼ìš°ì € ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.")

input_mode = st.radio("ì…ë ¥ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”", ("í…ìŠ¤íŠ¸", "ìŒì„±"), horizontal=True)
input_text = ""

if input_mode == "í…ìŠ¤íŠ¸":
    input_text = st.text_input("ë¹„ì„œì—ê²Œ í•  ë§ì„ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: ì˜¤ëŠ˜ ì¼ì • ì•Œë ¤ì¤˜")
elif input_mode == "ìŒì„±":
    st.write("ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§ˆì´í¬ë¡œ ë§í•˜ì„¸ìš” ğŸ‘‡")
    audio = mic_recorder(start_prompt="ğŸ¤ ë§í•˜ê¸° ì‹œì‘", stop_prompt="â¹ï¸ ë…¹ìŒ ì¢…ë£Œ", key="recorder")
    if audio:
        st.audio(audio['bytes'], format="audio/webm")
        input_text = recognize_speech_web(audio['bytes'])

################################################################################
# 8. ì‚¬ìš©ì ìš”ì²­ ë¶„ê¸° ì²˜ë¦¬ ë° ì‘ë‹µ ìƒì„±
################################################################################
if input_text:
    if "ì´ë©”ì¼" in input_text or "ì¼ì •" in input_text:
        response = agent.run(input_text)
    elif "íšŒì˜" in input_text or "ì •ë³´" in input_text:
        response = rag_chain.invoke(input_text)
    else:
        response = conversation.invoke(
            {"message": input_text},
            config={"configurable": {"session_id": "user-session"}}
        )

################################################################################
# 9. ì‘ë‹µ ì¶œë ¥
################################################################################
    st.subheader("ğŸ“ ë¹„ì„œ ë‹µë³€")
    st.write(response)

################################################################################
# 10. ìŒì„± ì¶œë ¥ (TTS)
################################################################################
    st.subheader("ğŸ”Š ìŒì„± ì¶œë ¥")
    try:
        tts_engine = pyttsx3.init()
        tts_engine.say(response)
        tts_engine.runAndWait()
    except Exception as e:
        st.warning("TTS ì‹¤í–‰ ì˜¤ë¥˜: pyttsx3 ëª¨ë“ˆì´ ì •ìƒ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

################################################################################
# 11. ëŒ€í™” ì´ë ¥ ì €ì¥ ë° ì¶œë ¥
################################################################################
    if 'history' not in st.session_state:
        st.session_state.history = []
    st.session_state.history.append(("ğŸ‘¤ ì‚¬ìš©ì", input_text))
    st.session_state.history.append(("ğŸ¤– ë¹„ì„œ", response))

    st.subheader("ğŸ—‚ï¸ ëŒ€í™” ì´ë ¥")
    for role, msg in st.session_state.history:
        st.markdown(f"**{role}:** {msg}")
